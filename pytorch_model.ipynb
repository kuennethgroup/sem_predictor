{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch model framework for A15 Phase prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lukas/Masterthesis/data/02_resize-convert\n",
      "                                   name  A15 Phase  Chromium  Silicon  \\\n",
      "0  F006_044_Detail1_500x20kV_oan_M1.tif      55.02      66.3     10.8   \n",
      "1  F006_044_Detail2_500x20kV_oan_M2.tif      54.59      66.3     10.8   \n",
      "2  F006_044_Detail3_500x20kV_oan_M3.tif      54.12      66.3     10.8   \n",
      "3  F006_044_Detail4_500x20kV_oan_M4.tif      50.51      66.3     10.8   \n",
      "4  F006_044_Detail5_500x20kV_oan_M5.tif      55.92      66.3     10.8   \n",
      "\n",
      "   Germanium  Molybdenum  Platinum  \n",
      "0        1.7        21.3       0.0  \n",
      "1        1.7        21.3       0.0  \n",
      "2        1.7        21.3       0.0  \n",
      "3        1.7        21.3       0.0  \n",
      "4        1.7        21.3       0.0  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('/home/lukas/Masterthesis/data/00_raw/Phasenanteile_ges.csv')\n",
    "\n",
    "# Get the list of image files\n",
    "image_folder = '/home/lukas/Masterthesis/data/02_resize-convert'  # Adjust this path\n",
    "\n",
    "print(image_folder)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image format:  TIFF\n",
      "image mode:  L\n",
      "image size:  (224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:371236): Gtk-WARNING **: 10:05:45.700: cannot open display: \n"
     ]
    }
   ],
   "source": [
    "image_path = \"/home/lukas/Masterthesis/data/02_resize-convert/F006_039_Detail4_500x20kV_oan_M4.tif\"\n",
    "img = Image.open(image_path)\n",
    "\n",
    "print(\"image format: \", img.format)\n",
    "print(\"image mode: \", img.mode)\n",
    "print(\"image size: \", img.size) \n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 7) (20, 7) (20, 7)\n",
      "                                    name  A15 Phase  Chromium  Silicon  \\\n",
      "3   F006_044_Detail4_500x20kV_oan_M4.tif      50.51      66.3     10.8   \n",
      "96     F012_032_Detail11_2kx20kV_A33.tif      19.39      90.6      9.4   \n",
      "56                       F690_108_M5.tif      33.00      90.9      9.1   \n",
      "69                       F690_111_M3.tif      31.10      90.7      7.0   \n",
      "2   F006_044_Detail3_500x20kV_oan_M3.tif      54.12      66.3     10.8   \n",
      "\n",
      "    Germanium  Molybdenum  Platinum  \n",
      "3         1.7        21.3       0.0  \n",
      "96        0.0         0.0       0.0  \n",
      "56        0.0         0.0       0.0  \n",
      "69        2.2         0.0       0.0  \n",
      "2         1.7        21.3       0.0                                       name  A15 Phase  Chromium  Silicon  \\\n",
      "62                       F690_122_M1.tif      23.90     89.90     7.80   \n",
      "40        F011_015_11_1kx20kV_com_M2.tif      13.51     88.91     7.51   \n",
      "93     F012_032_Detail10_2kx20kV_A30.tif      28.39     90.60     9.40   \n",
      "18  F006_040_Detail4_500x20kV_oan_M4.tif      11.39     87.90     6.40   \n",
      "81      F012_024_Detail4_1kx20kV_A57.tif      17.18     90.40     7.80   \n",
      "\n",
      "    Germanium  Molybdenum  Platinum  \n",
      "62       0.00        2.00       0.0  \n",
      "40       1.81        1.77       0.0  \n",
      "93       0.00        0.00       0.0  \n",
      "18       0.00        5.70       0.0  \n",
      "81       1.80        0.00       0.0                                       name  A15 Phase  Chromium  Silicon  \\\n",
      "39        F011_015_11_1kx20kV_com_M1.tif      14.05     88.91     7.51   \n",
      "6   F006_043_Detail2_500x20kV_oan_M2.tif      50.84     68.60     2.00   \n",
      "95      F012_032_Detail9_20x20kV_A27.tif      18.08     90.60     9.40   \n",
      "49                       F690_135_M3.tif      11.33     93.20     6.60   \n",
      "46                       F690_136_M5.tif      21.50     92.00     7.90   \n",
      "\n",
      "    Germanium  Molybdenum  Platinum  \n",
      "39       1.81        1.77       0.0  \n",
      "6       11.20       18.30       0.0  \n",
      "95       0.00        0.00       0.0  \n",
      "49       0.00        0.00       0.0  \n",
      "46       0.00        0.00       0.0  \n",
      "the length of the image files folder is:  97\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg', '.tif'))]\n",
    "\n",
    "# Ensure that all image files have corresponding composition data\n",
    "df = df[df.iloc[:, 0].isin(image_files)]\n",
    "\n",
    "# Perform the train-test split\n",
    "train_val_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=0.25, random_state=42)\n",
    "\n",
    "print(train_data.shape, test_data.shape, val_data.shape)\n",
    "print(train_data.head(), test_data.head(), val_data.head())\n",
    "print(f\"the length of the image files folder is: \",len(image_files))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Imgs to destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 57 images to /home/lukas/Masterthesis/pytorch/data/train.\n",
      "Copied 20 images to /home/lukas/Masterthesis/pytorch/data/test.\n",
      "Copied 20 images to /home/lukas/Masterthesis/pytorch/data/val.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "source_folder = \"/home/lukas/Masterthesis/data/02_resize-convert\"\n",
    "train_destination_folder = \"/home/lukas/Masterthesis/pytorch/data/train\"\n",
    "test_destination_folder = \"/home/lukas/Masterthesis/pytorch/data/test\"\n",
    "val_destination_folder = \"/home/lukas/Masterthesis/pytorch/data/val\"\n",
    "\n",
    "# Create the destination folders if they do not exist\n",
    "if not os.path.exists(train_destination_folder):\n",
    "    os.makedirs(train_destination_folder)\n",
    "if not os.path.exists(test_destination_folder):\n",
    "    os.makedirs(test_destination_folder)\n",
    "if not os.path.exists(val_destination_folder):\n",
    "    os.makedirs(val_destination_folder)\n",
    "\n",
    "all_images = os.listdir(source_folder)\n",
    "\n",
    "# Train img\n",
    "images_to_copy = [img for img in all_images if img in train_data['name'].values]\n",
    "\n",
    "for image in images_to_copy:\n",
    "    source_path = os.path.join(source_folder, image)\n",
    "    destination_path = os.path.join(train_destination_folder, image)\n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "print(f\"Copied {len(images_to_copy)} images to {train_destination_folder}.\")\n",
    "\n",
    "# Test img\n",
    "images_to_copy = [img for img in all_images if img in test_data['name'].values]\n",
    "for image in images_to_copy:\n",
    "    source_path = os.path.join(source_folder, image)\n",
    "    destination_path = os.path.join(test_destination_folder, image)\n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "print(f\"Copied {len(images_to_copy)} images to {test_destination_folder}.\")\n",
    "\n",
    "# Val img\n",
    "images_to_copy = [img for img in all_images if img in val_data['name'].values]\n",
    "for image in images_to_copy:\n",
    "    source_path = os.path.join(source_folder, image)\n",
    "    destination_path = os.path.join(val_destination_folder, image)\n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "print(f\"Copied {len(images_to_copy)} images to {val_destination_folder}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking training images:\n",
      "Train image in dataframe: F012_024_Detail2_1kx20kV_A50.tif\n",
      "Train image in dataframe: F006_041_Detail2_500x20kV_oan_M2.tif\n",
      "Train image in dataframe: F011_010_1_1kx20kV_com_M3.tif\n",
      "Train image in dataframe: F690_108_M1.tif\n",
      "Train image in dataframe: F011_011_2_1kx20kV_com_M1.tif\n",
      "Train image in dataframe: F690_108_M5.tif\n",
      "Train image in dataframe: F006_040_Detail5_500x20kV_oan_M5.tif\n",
      "Train image in dataframe: F006_044_Detail2_500x20kV_oan_M2.tif\n",
      "Train image in dataframe: F690_111_M3.tif\n",
      "Train image in dataframe: F006_040_Detail1_500x20kV_oan_M1.tif\n",
      "Train image in dataframe: F011_013_11_1kx20kV_com_M1.tif\n",
      "Train image in dataframe: F012_032_Detail10_2kx20kV_A29.tif\n",
      "Train image in dataframe: F006_044_Detail3_500x20kV_oan_M3.tif\n",
      "Train image in dataframe: F011_011_11_1kx20kV_com_M1.tif\n",
      "Train image in dataframe: F012_051_Detail5_2kx20kV_A71.tif\n",
      "Train image in dataframe: F006_044_Detail4_500x20kV_oan_M4.tif\n",
      "Train image in dataframe: F690_111_M2.tif\n",
      "Train image in dataframe: F690_122_M5.tif\n",
      "Train image in dataframe: F012_051_Detail1_2kx20kV_A58.tif\n",
      "Train image in dataframe: F690_136_M2.tif\n",
      "Train image in dataframe: F012_024_Detail3_1kx20kV_A54.tif\n",
      "Train image in dataframe: F690_135_M5.tif\n",
      "Train image in dataframe: F011_013_11_1kx20kV_com_M4.tif\n",
      "Train image in dataframe: F690_119_M1.tif\n",
      "Train image in dataframe: F690_108_M2.tif\n",
      "Train image in dataframe: F006_039_Detail1_500x20kV_oan_M1.tif\n",
      "Train image in dataframe: F690_111_M5.tif\n",
      "Train image in dataframe: F690_136_M4.tif\n",
      "Train image in dataframe: F006_040_Detail3_500x20kV_oan_M3.tif\n",
      "Train image in dataframe: F006_039_Detail2_500x20kV_oan_M2.tif\n",
      "Train image in dataframe: F690_135_M4.tif\n",
      "Train image in dataframe: F690_121_M2.tif\n",
      "Train image in dataframe: F006_039_Detail5_500x20kV_oan_M5.tif\n",
      "Train image in dataframe: F690_121_M4.tif\n",
      "Train image in dataframe: F012_032_Detail11_2kx20kV_A32.tif\n",
      "Train image in dataframe: F012_036_Detail1-1_2kx20kV_A21.tif\n",
      "Train image in dataframe: F690_108_M3.tif\n",
      "Train image in dataframe: F012_051_Detail5_2kx20kV_A69.tif\n",
      "Train image in dataframe: F690_121_M1.tif\n",
      "Train image in dataframe: F012_036_Detail5-1_2kx20kV_A29.tif\n",
      "Train image in dataframe: F011_005_1_1kx20kV_com_M1.tif\n",
      "Train image in dataframe: F012_032_Detail11_2kx20kV_A33.tif\n",
      "Train image in dataframe: F006_043_Detail3_500x20kV_oan_M3.tif\n",
      "Train image in dataframe: F690_111_M1.tif\n",
      "Train image in dataframe: F006_043_Detail1_500x20kV_oan_M1.tif\n",
      "Train image in dataframe: F012_051_Detail1_2kx20kV_A56.tif\n",
      "Train image in dataframe: F012_024_Detail1_1kx20kV_A47.tif\n",
      "Train image in dataframe: F012_036_Detail4-1_2kx20kV_A27.tif\n",
      "Train image in dataframe: F690_121_M3.tif\n",
      "Train image in dataframe: F012_024_Detail6_1kx20kV_A64.tif\n",
      "Train image in dataframe: F011_011_11_1kx20kV_com_M4.tif\n",
      "Train image in dataframe: F690_135_M2.tif\n",
      "Train image in dataframe: F011_010_1_1kx20kV_com_M4.tif\n",
      "Train image in dataframe: F011_010_1_1kx20kV_com_M1.tif\n",
      "Train image in dataframe: F006_043_Detail5_500x20kV_oan_M5.tif\n",
      "Train image in dataframe: F690_111_M4.tif\n",
      "Train image in dataframe: F011_011_11_1kx20kV_com_M2.tif\n",
      "\n",
      "Checking test images:\n",
      "Test image in dataframe: F011_005_1_1kx20kV_com_M2.tif\n",
      "Test image in dataframe: F006_041_Detail3_500x20kV_oan_M3.tif\n",
      "Test image in dataframe: F012_036_Detail2-1_2kx20kV_A23.tif\n",
      "Test image in dataframe: F690_122_M1.tif\n",
      "Test image in dataframe: F006_039_Detail3_500x20kV_oan_M3.tif\n",
      "Test image in dataframe: F006_040_Detail4_500x20kV_oan_M4.tif\n",
      "Test image in dataframe: F690_119_M4.tif\n",
      "Test image in dataframe: F011_010_1_1kx20kV_com_M5.tif\n",
      "Test image in dataframe: F690_135_M1.tif\n",
      "Test image in dataframe: F690_136_M3.tif\n",
      "Test image in dataframe: F012_051_Detail3_2kx20kV_A61.tif\n",
      "Test image in dataframe: F006_041_Detail1_500x20kV_oan_M1.tif\n",
      "Test image in dataframe: F690_136_M1.tif\n",
      "Test image in dataframe: F690_122_M3.tif\n",
      "Test image in dataframe: F012_032_Detail10_2kx20kV_A30.tif\n",
      "Test image in dataframe: F006_044_Detail5_500x20kV_oan_M5.tif\n",
      "Test image in dataframe: F011_015_11_1kx20kV_com_M2.tif\n",
      "Test image in dataframe: F006_044_Detail1_500x20kV_oan_M1.tif\n",
      "Test image in dataframe: F012_024_Detail4_1kx20kV_A57.tif\n",
      "Test image in dataframe: F690_119_M2.tif\n",
      "\n",
      "Checking validation images:\n",
      "Validation image in dataframe: F006_041_Detail4_500x20kV_oan_M4.tif\n",
      "Validation image in dataframe: F012_036_Detail3-1_2kx20kV_A25.tif\n",
      "Validation image in dataframe: F006_039_Detail4_500x20kV_oan_M4.tif\n",
      "Validation image in dataframe: F011_011_2_1kx20kV_com_M4.tif\n",
      "Validation image in dataframe: F690_136_M5.tif\n",
      "Validation image in dataframe: F690_122_M2.tif\n",
      "Validation image in dataframe: F690_122_M4.tif\n",
      "Validation image in dataframe: F011_010_1_1kx20kV_com_M2.tif\n",
      "Validation image in dataframe: F690_121_M5.tif\n",
      "Validation image in dataframe: F006_041_Detail5_500x20kV_oan_M5.tif\n",
      "Validation image in dataframe: F690_119_M5.tif\n",
      "Validation image in dataframe: F690_135_M3.tif\n",
      "Validation image in dataframe: F006_040_Detail2_500x20kV_oan_M2.tif\n",
      "Validation image in dataframe: F690_108_M4.tif\n",
      "Validation image in dataframe: F690_119_M3.tif\n",
      "Validation image in dataframe: F006_043_Detail4_500x20kV_oan_M4.tif\n",
      "Validation image in dataframe: F006_043_Detail2_500x20kV_oan_M2.tif\n",
      "Validation image in dataframe: F011_015_11_1kx20kV_com_M4.tif\n",
      "Validation image in dataframe: F011_015_11_1kx20kV_com_M1.tif\n",
      "Validation image in dataframe: F012_032_Detail9_20x20kV_A27.tif\n"
     ]
    }
   ],
   "source": [
    "# Check if images are also listed in the dataframes\n",
    "\n",
    "\n",
    "# Check train folder\n",
    "print(\"Checking training images:\")\n",
    "for img in os.listdir(train_destination_folder):\n",
    "    if img not in train_data['name'].values:\n",
    "        print(f\"Train image not in dataframe: {img}\")\n",
    "    else:\n",
    "        print(f\"Train image in dataframe: {img}\")\n",
    "\n",
    "# Check test folder\n",
    "print(\"\\nChecking test images:\")\n",
    "for img in os.listdir(test_destination_folder):\n",
    "    if img not in test_data['name'].values:\n",
    "        print(f\"Test image not in dataframe: {img}\")\n",
    "    else:\n",
    "        print(f\"Test image in dataframe: {img}\")\n",
    "\n",
    "# Check validation folder (may be empty)\n",
    "print(\"\\nChecking validation images:\")\n",
    "for img in os.listdir(val_destination_folder):\n",
    "    if img not in val_data['name'].values:\n",
    "        print(f\"Validation image not in dataframe: {img}\")\n",
    "    else:\n",
    "        print(f\"Validation image in dataframe: {img}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists: /home/lukas/Masterthesis/pytorch/data/train_img_augmented\n",
      "Total images processed: 456\n",
      "Transformed images saved in: /home/lukas/Masterthesis/pytorch/data/train_img_augmented\n"
     ]
    }
   ],
   "source": [
    "# Augementation for the images\n",
    "\n",
    "def rotate_and_flip_images(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Rotates and flips images from the input folder, appending numbers 1-8 to the filenames.\n",
    "    Saves all transformed images in the specified output folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(f\"Created output directory: {output_folder}\")\n",
    "    else:\n",
    "        print(f\"Output directory already exists: {output_folder}\")\n",
    "\n",
    "    processed_count = 0\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            img = Image.open(image_path)\n",
    "\n",
    "            # Define transformations\n",
    "            transformations = [\n",
    "                (img, \"1\"),  # Original\n",
    "                (img.rotate(90, expand=True), \"2\"),\n",
    "                (img.rotate(180, expand=True), \"3\"),\n",
    "                (img.rotate(270, expand=True), \"4\"),\n",
    "                (img.transpose(Image.FLIP_LEFT_RIGHT), \"5\"),\n",
    "                (img.transpose(Image.FLIP_LEFT_RIGHT).rotate(90, expand=True), \"6\"),\n",
    "                (img.transpose(Image.FLIP_LEFT_RIGHT).rotate(180, expand=True), \"7\"),\n",
    "                (img.transpose(Image.FLIP_LEFT_RIGHT).rotate(270, expand=True), \"8\"),\n",
    "            ]\n",
    "\n",
    "            # Save transformed images\n",
    "            for transformed_img, suffix in transformations:\n",
    "                new_filename = f\"{os.path.splitext(filename)[0]}_{suffix}.tif\"\n",
    "                transformed_img.save(os.path.join(output_folder, new_filename))\n",
    "                processed_count += 1\n",
    "\n",
    "    return processed_count\n",
    "\n",
    "# Example usage\n",
    "input_folder = '/home/lukas/Masterthesis/pytorch/data/train'  # Replace with your input folder path\n",
    "output_folder = '/home/lukas/Masterthesis/pytorch/data/train_img_augmented'  # Replace with your desired output folder path\n",
    "\n",
    "processed_images = rotate_and_flip_images(input_folder, output_folder)\n",
    "print(f\"Total images processed: {processed_images}\")\n",
    "print(f\"Transformed images saved in: {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation for dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456, 7)\n"
     ]
    }
   ],
   "source": [
    "# Augmentation for the train_data dataframe\n",
    "\n",
    "def replicated_df_rows(train_data):\n",
    "    new_rows = []\n",
    "\n",
    "    for index, row in train_data.iterrows():\n",
    "        for i in range(1, 9):\n",
    "            modified_row = row.copy()\n",
    "            # Split the name into base and extension using rsplit\n",
    "            name_parts = row['name'].rsplit('.', 1)\n",
    "            if len(name_parts) == 2:\n",
    "                base_name, extension = name_parts\n",
    "                # Insert the number before the extension\n",
    "                modified_row['name'] = f\"{base_name}_{i}.{extension}\"\n",
    "            else:\n",
    "                # If no extension is present, simply append the number\n",
    "                modified_row['name'] = f\"{row['name']}_{i}\"\n",
    "            new_rows.append(modified_row)\n",
    "        \n",
    "    return pd.DataFrame(new_rows)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "train_data = replicated_df_rows(train_data)\n",
    "\n",
    "print(train_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-Path Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456, 8)\n",
      "                                          image_path  \\\n",
      "3  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "3  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "3  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "3  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "3  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "\n",
      "                                     name  A15 Phase  Chromium  Silicon  \\\n",
      "3  F006_044_Detail4_500x20kV_oan_M4_1.tif      50.51      66.3     10.8   \n",
      "3  F006_044_Detail4_500x20kV_oan_M4_2.tif      50.51      66.3     10.8   \n",
      "3  F006_044_Detail4_500x20kV_oan_M4_3.tif      50.51      66.3     10.8   \n",
      "3  F006_044_Detail4_500x20kV_oan_M4_4.tif      50.51      66.3     10.8   \n",
      "3  F006_044_Detail4_500x20kV_oan_M4_5.tif      50.51      66.3     10.8   \n",
      "\n",
      "   Germanium  Molybdenum  Platinum  \n",
      "3        1.7        21.3       0.0  \n",
      "3        1.7        21.3       0.0  \n",
      "3        1.7        21.3       0.0  \n",
      "3        1.7        21.3       0.0  \n",
      "3        1.7        21.3       0.0  \n",
      "(20, 8)\n",
      "                                           image_path  \\\n",
      "62  /home/lukas/Masterthesis/pytorch/data/test/F69...   \n",
      "40  /home/lukas/Masterthesis/pytorch/data/test/F01...   \n",
      "93  /home/lukas/Masterthesis/pytorch/data/test/F01...   \n",
      "18  /home/lukas/Masterthesis/pytorch/data/test/F00...   \n",
      "81  /home/lukas/Masterthesis/pytorch/data/test/F01...   \n",
      "\n",
      "                                    name  A15 Phase  Chromium  Silicon  \\\n",
      "62                       F690_122_M1.tif      23.90     89.90     7.80   \n",
      "40        F011_015_11_1kx20kV_com_M2.tif      13.51     88.91     7.51   \n",
      "93     F012_032_Detail10_2kx20kV_A30.tif      28.39     90.60     9.40   \n",
      "18  F006_040_Detail4_500x20kV_oan_M4.tif      11.39     87.90     6.40   \n",
      "81      F012_024_Detail4_1kx20kV_A57.tif      17.18     90.40     7.80   \n",
      "\n",
      "    Germanium  Molybdenum  Platinum  \n",
      "62       0.00        2.00       0.0  \n",
      "40       1.81        1.77       0.0  \n",
      "93       0.00        0.00       0.0  \n",
      "18       0.00        5.70       0.0  \n",
      "81       1.80        0.00       0.0  \n",
      "(20, 8)\n",
      "                                           image_path  \\\n",
      "39  /home/lukas/Masterthesis/pytorch/data/val/F011...   \n",
      "6   /home/lukas/Masterthesis/pytorch/data/val/F006...   \n",
      "95  /home/lukas/Masterthesis/pytorch/data/val/F012...   \n",
      "49  /home/lukas/Masterthesis/pytorch/data/val/F690...   \n",
      "46  /home/lukas/Masterthesis/pytorch/data/val/F690...   \n",
      "\n",
      "                                    name  A15 Phase  Chromium  Silicon  \\\n",
      "39        F011_015_11_1kx20kV_com_M1.tif      14.05     88.91     7.51   \n",
      "6   F006_043_Detail2_500x20kV_oan_M2.tif      50.84     68.60     2.00   \n",
      "95      F012_032_Detail9_20x20kV_A27.tif      18.08     90.60     9.40   \n",
      "49                       F690_135_M3.tif      11.33     93.20     6.60   \n",
      "46                       F690_136_M5.tif      21.50     92.00     7.90   \n",
      "\n",
      "    Germanium  Molybdenum  Platinum  \n",
      "39       1.81        1.77       0.0  \n",
      "6       11.20       18.30       0.0  \n",
      "95       0.00        0.00       0.0  \n",
      "49       0.00        0.00       0.0  \n",
      "46       0.00        0.00       0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_folder = output_folder\n",
    "test_folder = test_destination_folder\n",
    "val_folder  = val_destination_folder\n",
    "\n",
    "# Function to get the full path of an image\n",
    "def get_image_path_train(filename):\n",
    "    return os.path.join(train_folder, filename)\n",
    "    \n",
    "    # Add a new column 'image_path' with the full path to each image\n",
    "train_data['image_path'] = train_data.iloc[:, 0].apply(get_image_path_train)\n",
    "    \n",
    "# Move 'image_path' column to the first position\n",
    "cols = ['image_path'] + [col for col in train_data.columns if col != 'image_path']\n",
    "train_data = train_data[cols]\n",
    "    \n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_data.head())\n",
    "\n",
    "\n",
    "# Function to get the full path of an image\n",
    "def get_image_path_test(filename):\n",
    "    return os.path.join(test_folder, filename)\n",
    "\n",
    "    # Add a new column 'image_path' with the full path to each image\n",
    "test_data['image_path'] = test_data.iloc[:, 0].apply(get_image_path_test)\n",
    "    \n",
    "# Move 'image_path' column to the first position\n",
    "cols = ['image_path'] + [col for col in test_data.columns if col != 'image_path']\n",
    "test_data = test_data[cols]\n",
    "    \n",
    "\n",
    "# Function to get the full path of an image\n",
    "def get_image_path_val(filename):\n",
    "    return os.path.join(val_folder, filename)\n",
    "\n",
    "    # Add a new column 'image_path' with the full path to each image\n",
    "val_data['image_path'] = val_data.iloc[:, 0].apply(get_image_path_val)\n",
    "    \n",
    "# Move 'image_path' column to the first position\n",
    "cols = ['image_path'] + [col for col in val_data.columns if col != 'image_path']\n",
    "val_data = val_data[cols]\n",
    "    \n",
    "    \n",
    "print(test_data.shape)\n",
    "print(test_data.head())\n",
    "print(val_data.shape)\n",
    "print(val_data.head())\n",
    "\n",
    "# df_train.to_csv('/home/lukas/Masterthesis/pytorch/train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selector Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shuffled DataFrame:\n",
      "                                          image_path  \\\n",
      "0  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "1  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "2  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "3  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "4  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "\n",
      "                                     name  A15 Phase  Chromium  Silicon  \\\n",
      "0  F006_039_Detail5_500x20kV_oan_M5_6.tif      31.41      88.9      9.1   \n",
      "1  F006_044_Detail3_500x20kV_oan_M3_8.tif      54.12      66.3     10.8   \n",
      "2      F012_051_Detail5_2kx20kV_A69_5.tif      13.09      90.4      7.8   \n",
      "3      F012_051_Detail5_2kx20kV_A71_3.tif      12.60      90.4      7.8   \n",
      "4  F006_040_Detail1_500x20kV_oan_M1_4.tif      10.35      87.9      6.4   \n",
      "\n",
      "   Germanium  Molybdenum  Platinum  \n",
      "0        0.0         2.0       0.0  \n",
      "1        1.7        21.3       0.0  \n",
      "2        1.8         0.0       0.0  \n",
      "3        1.8         0.0       0.0  \n",
      "4        0.0         5.7       0.0  \n",
      "\n",
      "Shuffled DataFrame:\n",
      "                                          image_path  \\\n",
      "0  /home/lukas/Masterthesis/pytorch/data/test/F69...   \n",
      "1  /home/lukas/Masterthesis/pytorch/data/test/F00...   \n",
      "2  /home/lukas/Masterthesis/pytorch/data/test/F00...   \n",
      "3  /home/lukas/Masterthesis/pytorch/data/test/F01...   \n",
      "4  /home/lukas/Masterthesis/pytorch/data/test/F00...   \n",
      "\n",
      "                                   name  A15 Phase  Chromium  Silicon  \\\n",
      "0                       F690_122_M1.tif      23.90     89.90     7.80   \n",
      "1  F006_041_Detail3_500x20kV_oan_M3.tif      45.44     66.30     0.00   \n",
      "2  F006_044_Detail5_500x20kV_oan_M5.tif      55.92     66.30    10.80   \n",
      "3        F011_015_11_1kx20kV_com_M2.tif      13.51     88.91     7.51   \n",
      "4  F006_041_Detail1_500x20kV_oan_M1.tif      48.77     66.30     0.00   \n",
      "\n",
      "   Germanium  Molybdenum  Platinum  \n",
      "0       0.00        2.00       0.0  \n",
      "1      13.40       20.40       0.0  \n",
      "2       1.70       21.30       0.0  \n",
      "3       1.81        1.77       0.0  \n",
      "4      13.40       20.40       0.0  \n",
      "\n",
      "Shuffled DataFrame:\n",
      "                                          image_path  \\\n",
      "0  /home/lukas/Masterthesis/pytorch/data/val/F011...   \n",
      "1  /home/lukas/Masterthesis/pytorch/data/val/F011...   \n",
      "2  /home/lukas/Masterthesis/pytorch/data/val/F006...   \n",
      "3  /home/lukas/Masterthesis/pytorch/data/val/F006...   \n",
      "4  /home/lukas/Masterthesis/pytorch/data/val/F011...   \n",
      "\n",
      "                                   name  A15 Phase  Chromium  Silicon  \\\n",
      "0        F011_015_11_1kx20kV_com_M1.tif      14.05     88.91     7.51   \n",
      "1         F011_011_2_1kx20kV_com_M4.tif       3.61     90.57     1.73   \n",
      "2  F006_043_Detail4_500x20kV_oan_M4.tif      44.85     68.60     2.00   \n",
      "3  F006_043_Detail2_500x20kV_oan_M2.tif      50.84     68.60     2.00   \n",
      "4        F011_015_11_1kx20kV_com_M4.tif      16.21     88.91     7.51   \n",
      "\n",
      "   Germanium  Molybdenum  Platinum  \n",
      "0       1.81        1.77      0.00  \n",
      "1       3.73        5.73      7.73  \n",
      "2      11.20       18.30      0.00  \n",
      "3      11.20       18.30      0.00  \n",
      "4       1.81        1.77      0.00  \n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"\\nShuffled DataFrame:\")\n",
    "print(train_data.head())\n",
    "\n",
    "test_data = test_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"\\nShuffled DataFrame:\")\n",
    "print(test_data.head())\n",
    "\n",
    "val_data = val_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"\\nShuffled DataFrame:\")\n",
    "print(val_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data length: 2736\n",
      "Test data length: 120\n",
      "Validation data length: 120\n",
      "\n",
      "Sample of processed train data:\n",
      "                                          image_path  \\\n",
      "0  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "1  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "2  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "3  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "4  /home/lukas/Masterthesis/pytorch/data/train_im...   \n",
      "\n",
      "                                     name  A15 Phase  Chromium  Silicon  \\\n",
      "0      F012_051_Detail1_2kx20kV_A56_1.tif      13.28      90.4      7.8   \n",
      "1  F006_043_Detail3_500x20kV_oan_M3_4.tif      47.07      68.6      2.0   \n",
      "2    F012_036_Detail5-1_2kx20kV_A29_6.tif      21.20      90.6      9.4   \n",
      "3                       F690_136_M4_3.tif      23.76      92.0      7.9   \n",
      "4                       F690_121_M1_7.tif      17.50      90.9      6.7   \n",
      "\n",
      "   Germanium  Molybdenum  Platinum     selector_vector  composition_value  \\\n",
      "0        1.8         0.0       0.0  [0, 0, 0, 0, 0, 1]                  0   \n",
      "1       11.2        18.3       0.0  [0, 0, 0, 1, 0, 0]                  0   \n",
      "2        0.0         0.0       0.0  [0, 0, 1, 0, 0, 0]                  0   \n",
      "3        0.0         0.0       0.0  [1, 0, 0, 0, 0, 0]                  0   \n",
      "4        0.0         0.0       2.1  [0, 0, 0, 1, 0, 0]                  0   \n",
      "\n",
      "  Compo_name   value  \n",
      "0   Platinum -1.0000  \n",
      "1  Germanium -0.7760  \n",
      "2    Silicon -0.8120  \n",
      "3  A15_Phase -0.5248  \n",
      "4  Germanium -1.0000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_dataset(data, random_state=42):\n",
    "    \"\"\"\n",
    "    Process a dataset by:\n",
    "    1. Adding selector vectors\n",
    "    2. Replicating rows for each composition type\n",
    "    3. Shuffling the data\n",
    "    4. Normalizing the value column\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input dataframe to process\n",
    "        random_state (int): Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed dataframe\n",
    "    \"\"\"\n",
    "    # Create initial selector vector and composition value\n",
    "    sv = np.array([0, 0, 0, 0, 0, 0])\n",
    "    data['selector_vector'] = data.apply(lambda x: sv, axis=1)\n",
    "    data['composition_value'] = data.apply(lambda x: 0, axis=1)\n",
    "    \n",
    "    # Mapping dictionary for compositions\n",
    "    mapping = {\n",
    "        0: (\"A15_Phase\", \"A15 Phase\"),\n",
    "        1: (\"Chromium\", \"Chromium\"),\n",
    "        2: (\"Silicon\", \"Silicon\"),\n",
    "        3: ('Germanium', 'Germanium'),\n",
    "        4: (\"Molybdenum\", \"Molybdenum\"),\n",
    "        5: (\"Platinum\", \"Platinum\")\n",
    "    }\n",
    "    \n",
    "    # Helper function to modify selector vector\n",
    "    def modify_selector_vector(row, index):\n",
    "        selector = row['selector_vector'].copy()\n",
    "        selector[:] = 0\n",
    "        selector[index] = 1\n",
    "        return selector\n",
    "    \n",
    "    # List to store replicated rows\n",
    "    new_rows = []\n",
    "    \n",
    "    # Replicate each row for each composition type\n",
    "    for idx, row in data.iterrows():\n",
    "        for i in range(6):\n",
    "            new_row = row.copy()\n",
    "            new_row['selector_vector'] = modify_selector_vector(row, i)\n",
    "            new_row['composition_value'] = 0\n",
    "            new_row['Compo_name'] = mapping[i][0]\n",
    "            new_row['value'] = row[mapping[i][1]]\n",
    "            new_rows.append(new_row)\n",
    "    \n",
    "    # Create new dataframe and reset index\n",
    "    processed_data = pd.DataFrame(new_rows).reset_index(drop=True)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    processed_data = processed_data.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    # Normalize the value column\n",
    "    processed_data = normalize_column_to_range(processed_data, 'value')\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Function to normalize a column to range [-1, 1]\n",
    "def normalize_column_to_range(dataframe, column_name):\n",
    "    col_min = 0\n",
    "    col_max = 100\n",
    "    dataframe[column_name] = -1 + 2 * (dataframe[column_name] - col_min) / (col_max - col_min)\n",
    "    return dataframe\n",
    "\n",
    "# Process each dataset\n",
    "train_data = process_dataset(train_data)\n",
    "test_data = process_dataset(test_data)\n",
    "# save the test data to .csv\n",
    "test_data.to_csv('/home/lukas/Masterthesis/pytorch/test_data.csv', index=False)\n",
    "val_data = process_dataset(val_data)\n",
    "\n",
    "# Print information about processed datasets\n",
    "print(f'Train data length: {len(train_data)}')\n",
    "print(f'Test data length: {len(test_data)}')\n",
    "print(f'Validation data length: {len(val_data)}')\n",
    "\n",
    "print(\"\\nSample of processed train data:\")\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1239779345.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    as\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomDataset class + SEMCNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, train_data, transform=None):\n",
    "        self.train_data = train_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = self.train_data.iloc[idx]['image_path']\n",
    "            selector = torch.tensor(self.train_data.iloc[idx]['selector_vector'], dtype=torch.float32)\n",
    "            value = torch.tensor(self.train_data.iloc[idx]['value'], dtype=torch.float32)\n",
    "\n",
    "            img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "\n",
    "            # Check if file exists\n",
    "            if not os.path.exists(img_path):\n",
    "                raise FileNotFoundError(f\"Image file not found: {img_path}\")\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            # Ensure img is a 3D tensor [C, H, W]\n",
    "            if img.dim() == 2:\n",
    "                img = img.unsqueeze(0)\n",
    "\n",
    "            return img, selector, value\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx}: {str(e)}\")\n",
    "            # Return a dummy sample or None\n",
    "            \n",
    "\n",
    "    def get_img_path(self, idx):\n",
    "        return self.train_data.iloc[idx]['image_path']\n",
    "    \n",
    "\n",
    "# model\n",
    "class SEM_Model(nn.Module):\n",
    "    def __init__(self, cnn_out_channels=32, fc_hidden1=512, fc_hidden2=256, dropout1=0.5, dropout2=0.3, selector_size=6):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # CNN Feature Extractor\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            # Second conv block\n",
    "            nn.Conv2d(in_channels=16, out_channels=cnn_out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(cnn_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            # Adaptive pooling -> fix size\n",
    "            nn.AdaptiveAvgPool2d((7, 7)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Calculate feature size after CNN\n",
    "        self.feature_size = cnn_out_channels * 7 * 7\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(self.feature_size + selector_size, fc_hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout1),\n",
    "            nn.Linear(fc_hidden1, fc_hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout2),\n",
    "            nn.Linear(fc_hidden2, 1)\n",
    "        )\n",
    "    def forward(self, img, selector):\n",
    "        features = self.feature_extractor(img)\n",
    "\n",
    "        if len(features.shape) == 1:\n",
    "            features = features.unsqueeze(0)\n",
    "\n",
    "        combined = torch.cat((features, selector), dim=1)\n",
    "        \n",
    "        return self.fc_layers(combined)\n",
    "    \n",
    "    def get_feature_size(self):\n",
    "        return self.feature_size\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train: DataLoader, Batch Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch Verification ===\n",
      "Batch 1:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 2:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 3:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 4:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 5:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 6:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 7:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 8:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 9:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 10:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 11:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 12:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 13:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 14:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 15:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 16:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 17:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 18:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 19:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 20:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 21:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 22:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 23:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 24:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 25:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 26:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 27:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 28:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 29:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 30:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 31:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 32:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 33:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 34:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 35:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 36:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 37:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 38:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 39:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 40:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 41:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 42:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 43:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 44:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 45:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 46:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 47:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 48:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 49:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 50:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 51:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 52:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 53:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 54:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 55:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 56:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 57:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 58:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 59:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 60:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 61:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 62:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 63:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 64:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 65:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 66:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 67:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 68:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 69:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 70:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 71:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 72:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 73:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 74:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 75:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 76:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 77:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 78:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 79:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 80:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 81:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 82:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 83:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 84:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 85:\n",
      " - Images: 32\n",
      " - Image Shape: torch.Size([32, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([32, 6])\n",
      " - Value Shape: torch.Size([32])\n",
      "\n",
      "Batch 86:\n",
      " - Images: 16\n",
      " - Image Shape: torch.Size([16, 1, 224, 224])\n",
      " - Selector Shape: torch.Size([16, 6])\n",
      " - Value Shape: torch.Size([16])\n",
      "\n",
      "\n",
      "=== Batch Summary ===\n",
      "Total Batches: 86\n",
      "Average Batch Size: 31.8\n",
      "\n",
      "First 3 Batches:\n",
      "Batch 1: 32 images, Shape: torch.Size([32, 1, 224, 224])\n",
      "Batch 2: 32 images, Shape: torch.Size([32, 1, 224, 224])\n",
      "Batch 3: 32 images, Shape: torch.Size([32, 1, 224, 224])\n",
      "\n",
      "Last 3 Batches:\n",
      "Batch 84: 32 images, Shape: torch.Size([32, 1, 224, 224])\n",
      "Batch 85: 32 images, Shape: torch.Size([32, 1, 224, 224])\n",
      "Batch 86: 16 images, Shape: torch.Size([16, 1, 224, 224])\n",
      "\n",
      "=== Final Check ===\n",
      "Expected Total Images: 2736\n",
      "Actual Total Images: 2736\n",
      "✓ All batches processed correctly\n",
      "\n",
      "=== Path Verification ===\n",
      "Example paths from Batch 1:\n",
      "- /home/lukas/Masterthesis/pytorch/data/train_img_augmented/F012_051_Detail1_2kx20kV_A56_1.tif\n",
      "- /home/lukas/Masterthesis/pytorch/data/train_img_augmented/F006_043_Detail3_500x20kV_oan_M3_4.tif\n",
      "- /home/lukas/Masterthesis/pytorch/data/train_img_augmented/F012_036_Detail5-1_2kx20kV_A29_6.tif\n",
      "\n",
      "Example paths from the last Batch:\n",
      "- /home/lukas/Masterthesis/pytorch/data/train_img_augmented/F012_051_Detail5_2kx20kV_A71_8.tif\n",
      "- /home/lukas/Masterthesis/pytorch/data/train_img_augmented/F011_005_1_1kx20kV_com_M1_1.tif\n",
      "- /home/lukas/Masterthesis/pytorch/data/train_img_augmented/F690_119_M1_7.tif\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  \n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_data, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# -------------------- Batch Verification --------------------\n",
    "\n",
    "# Complete run with batch overwatch\n",
    "total_images = 0\n",
    "all_batches_valid = True\n",
    "batch_info = []\n",
    "\n",
    "print(\"\\n=== Batch Verification ===\")\n",
    "try:\n",
    "    for batch_idx, (imgs, selectors, values) in enumerate(train_loader):\n",
    "        current_batch_size = imgs.size(0)\n",
    "        total_images += current_batch_size\n",
    "        \n",
    "        # Save batch info\n",
    "        batch_info.append({\n",
    "            'batch_num': batch_idx + 1,\n",
    "            'images': current_batch_size,\n",
    "            'shape': imgs.shape,\n",
    "            'selector_shape': selectors.shape\n",
    "        })\n",
    "        \n",
    "        # Immediate output for each batch\n",
    "        print(f\"Batch {batch_idx + 1}:\")\n",
    "        print(f\" - Images: {current_batch_size}\")\n",
    "        print(f\" - Image Shape: {imgs.shape}\")\n",
    "        print(f\" - Selector Shape: {selectors.shape}\")\n",
    "        print(f\" - Value Shape: {values.shape}\\n\")\n",
    "\n",
    "        # Size check for all batches\n",
    "        expected_batch_size = 32 if (batch_idx + 1) * 32 <= len(train_data) else len(train_data) % 32\n",
    "        if current_batch_size != expected_batch_size and batch_idx != len(train_loader) - 1:\n",
    "            print(f\"ERROR: Batch {batch_idx + 1} has {current_batch_size} images (expected: {expected_batch_size})\")\n",
    "            all_batches_valid = False\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in Batch {batch_idx + 1}: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Detailed summary\n",
    "print(\"\\n=== Batch Summary ===\")\n",
    "print(f\"Total Batches: {len(batch_info)}\")\n",
    "print(f\"Average Batch Size: {total_images / len(batch_info):.1f}\")\n",
    "\n",
    "print(\"\\nFirst 3 Batches:\")\n",
    "for info in batch_info[:3]:\n",
    "    print(f\"Batch {info['batch_num']}: {info['images']} images, Shape: {info['shape']}\")\n",
    "\n",
    "if len(batch_info) > 3:\n",
    "    print(\"\\nLast 3 Batches:\")\n",
    "    for info in batch_info[-3:]:\n",
    "        print(f\"Batch {info['batch_num']}: {info['images']} images, Shape: {info['shape']}\")\n",
    "\n",
    "# Final consistency check\n",
    "print(\"\\n=== Final Check ===\")\n",
    "print(f\"Expected Total Images: {len(train_data)}\")\n",
    "print(f\"Actual Total Images: {total_images}\")\n",
    "\n",
    "if total_images != len(train_data):\n",
    "    missing = len(train_data) - total_images\n",
    "    print(f\"CRITICAL ERROR: {missing} images are missing!\")\n",
    "elif not all_batches_valid:\n",
    "    print(\"WARNING: Some batches had incorrect sizes\")\n",
    "else:\n",
    "    print(\"✓ All batches processed correctly\")\n",
    "\n",
    "# Path check for the first and last batch\n",
    "print(\"\\n=== Path Verification ===\")\n",
    "print(\"Example paths from Batch 1:\")\n",
    "first_batch_indices = range(0, min(32, len(train_data)))\n",
    "for i in first_batch_indices[:3]:  # Show first 3 paths\n",
    "    print(f\"- {train_data.iloc[i]['image_path']}\")\n",
    "\n",
    "if len(train_data) > 32:\n",
    "    print(\"\\nExample paths from the last Batch:\")\n",
    "    last_batch_start = len(train_data) - (len(train_data) % 32)\n",
    "    for i in range(last_batch_start, last_batch_start + 3):\n",
    "        if i < len(train_data):\n",
    "            print(f\"- {train_data.iloc[i]['image_path']}\")\n",
    "\n",
    "# # Sample batch processing\n",
    "# sample_batch = next(iter(train_loader))\n",
    "# img_batch, selector_batch, value_batch = sample_batch\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     features = cnn(img_batch)\n",
    "\n",
    "# features_ex = torch.cat([features, selector_batch], 1)\n",
    "    \n",
    "# print(f\"Features shape: {features.shape}\")  # Should be [32, 1568]\n",
    "# print(f\"Selector shape: {selector_batch.shape}\")  # [32, 6]\n",
    "# print(f\"Combined shape: {features_ex.shape}\")  # [32, 1574]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Val: DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = CustomDataset(test_data, transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,  \n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_dataset = CustomDataset(val_data, transform=transform)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False, \n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Trials, Hyperparameters, Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import optuna\n",
    "import shutil\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "\n",
    "    # hyperparameters\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "        \"dropout1\": trial.suggest_float(\"dropout1\", 0.1, 0.3),\n",
    "        \"dropout2\": trial.suggest_float(\"dropout2\", 0.2, 0.4),\n",
    "        \"hidden1\": trial.suggest_int(\"hidden1\", 256, 512, step=64),\n",
    "        \"hidden2\": trial.suggest_int(\"hidden2\", 64, 256, step=64),\n",
    "        \"batch_size\": 32,\n",
    "        \"num_epochs\": 100,\n",
    "        \"patience\": 40\n",
    "    }\n",
    "    \n",
    "    # Initialize model with hyperparameters\n",
    "    model = SEM_Model(\n",
    "        dropout1=params['dropout1'],\n",
    "        dropout2=params['dropout2'],\n",
    "        fc_hidden1=params['hidden1'],\n",
    "        fc_hidden2=params['hidden2']\n",
    "    )\n",
    "    \n",
    "    return model, params\n",
    "\n",
    "\n",
    "def objective(trial, train_data, val_data, test_data=None, study_name=\"sem_study\"):\n",
    "\n",
    "    # Get trial number\n",
    "    trial_number = trial.number\n",
    "    \n",
    "    # Create model and get hyperparameters\n",
    "    model, params = create_model(trial)\n",
    "    \n",
    "    # Create trial directory\n",
    "    trial_dir = f\"{study_name}/trial_{trial_number}\"\n",
    "    os.makedirs(trial_dir, exist_ok=True)\n",
    "    \n",
    "    # Log trial start\n",
    "    with open(f'{study_name}/training.log', 'a') as log_file:\n",
    "        log_file.write(f\"\\n--- Trial {trial_number} Started ---\\n\")\n",
    "        log_file.write(f\"Parameters: lr={params['learning_rate']}, wd={params['weight_decay']}, \" +\n",
    "                      f\"d1={params['dropout1']}, d2={params['dropout2']}, \" +\n",
    "                      f\"h1={params['hidden1']}, h2={params['hidden2']}\\n\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=False)\n",
    "    \n",
    "    # Initialize variables for tracking training\n",
    "    start_time = time.time()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0  # For early stopping\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (imgs, selectors, values) in enumerate(train_loader):\n",
    "            # Transfer data to device\n",
    "            imgs = imgs.to(device)\n",
    "            selectors = selectors.to(device)\n",
    "            values = values.to(device).unsqueeze(1)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(imgs, selectors)\n",
    "            loss = criterion(outputs, values)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update statistics\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, selectors, values in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                selectors = selectors.to(device)\n",
    "                values = values.to(device).unsqueeze(1)\n",
    "                \n",
    "                outputs = model(imgs, selectors)\n",
    "                loss = criterion(outputs, values)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Store losses\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        elapsed = time.time() - start_time\n",
    "        elapsed_str = str(timedelta(seconds=int(elapsed)))\n",
    "        \n",
    "        # Log epoch results to common log file\n",
    "        log_message = (f\"Trial {trial_number} | Duration: {elapsed_str} | Epoch: {epoch+1}/{params['num_epochs']} | \"\n",
    "                      f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        with open(f'{study_name}/training.log', 'a') as log_file:\n",
    "            log_file.write(log_message + \"\\n\")\n",
    "        \n",
    "        # Check for best validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            counter = 0\n",
    "            \n",
    "            # Save best model for this trial\n",
    "            torch.save(model.state_dict(), os.path.join(trial_dir, 'best_model.pth'))\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter > params['patience']:\n",
    "                with open(f'{study_name}/training.log', 'a') as log_file:\n",
    "                    log_file.write(f\"Trial {trial_number} | Early stopping triggered at epoch {epoch+1}\\n\")\n",
    "                break\n",
    "    \n",
    "    # Save final model\n",
    "    # torch.save(model.state_dict(), os.path.join(trial_dir, 'final_model.pth')) # model of the last epoch where early stopping was triggered\n",
    "    \n",
    "    # Log completion\n",
    "    with open(f'{study_name}/training.log', 'a') as log_file:\n",
    "        log_file.write(f\"Trial {trial_number} completed with best validation loss: {best_val_loss:.4f}\\n\")\n",
    "    \n",
    "    # Return best validation loss for Optuna\n",
    "    return best_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hyperparameter_optimization(train_data, val_data, test_data=None, n_trials=5):\n",
    "    \n",
    "    # Initialize log file\n",
    "    with open('optuna_training.log', 'w') as log_file:\n",
    "        log_file.write(f\"Optuna study started at: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        log_file.write(f\"Number of trials: {n_trials}\\n\\n\")\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(\"trials\", exist_ok=True)\n",
    "    os.makedirs(\"best\", exist_ok=True)\n",
    "    \n",
    "    # Define the study\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    \n",
    "    # Run optimization\n",
    "    study.optimize(lambda trial: objective(trial, train_data, val_data, test_data), n_trials=n_trials)\n",
    "    \n",
    "    # Get best trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    # Log study results\n",
    "    with open('optuna_training.log', 'a') as log_file:\n",
    "        log_file.write(\"\\n--- Study Completed ---\\n\")\n",
    "        log_file.write(f\"Best trial: {best_trial.number}\\n\")\n",
    "        log_file.write(f\"Best value: {best_trial.value}\\n\")\n",
    "        log_file.write(\"Best hyperparameters:\\n\")\n",
    "        for key, value in best_trial.params.items():\n",
    "            log_file.write(f\"  {key}: {value}\\n\")\n",
    "    \n",
    "    # Copy best model to best directory\n",
    "    best_trial_dir = f\"trials/trial_{best_trial.number}\"\n",
    "    shutil.copy(\n",
    "        os.path.join(best_trial_dir, 'best_model.pth'),\n",
    "        os.path.join(\"best\", 'best_model.pth')\n",
    "    )\n",
    "    \n",
    "    # Print importance of hyperparameters\n",
    "    importance = optuna.importance.get_param_importances(study)\n",
    "    with open('optuna_training.log', 'a') as log_file:\n",
    "        log_file.write(\"\\n--- Hyperparameter Importance ---\\n\")\n",
    "        for param, score in importance.items():\n",
    "            log_file.write(f\"{param}: {score:.4f}\\n\")\n",
    "    \n",
    "    # Return study and best parameters\n",
    "    return study, best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(best_params, train_data, val_data, test_data=None):\n",
    "  \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(\"best\", exist_ok=True)\n",
    "    \n",
    "    # Initialize model with best hyperparameters\n",
    "    model = SEM_Model(\n",
    "        dropout1=best_params['dropout1'],\n",
    "        dropout2=best_params['dropout2'],\n",
    "        fc_hidden1=best_params['hidden1'],\n",
    "        fc_hidden2=best_params['hidden2']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=best_params['learning_rate'], \n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize variables for tracking training\n",
    "    start_time = time.time()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0  # For early stopping\n",
    "    \n",
    "    # Log training start\n",
    "    with open('optuna_training.log', 'a') as log_file:\n",
    "        log_file.write(\"\\n--- Training Final Model ---\\n\")\n",
    "        log_file.write(f\"Using best parameters: {best_params}\\n\")\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 1000\n",
    "    patience = 40\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (imgs, selectors, values) in enumerate(train_loader):\n",
    "            # Transfer data to device\n",
    "            imgs = imgs.to(device)\n",
    "            selectors = selectors.to(device)\n",
    "            values = values.to(device).unsqueeze(1)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(imgs, selectors)\n",
    "            loss = criterion(outputs, values)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update statistics\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, selectors, values in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                selectors = selectors.to(device)\n",
    "                values = values.to(device).unsqueeze(1)\n",
    "                \n",
    "                outputs = model(imgs, selectors)\n",
    "                loss = criterion(outputs, values)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Store losses\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(avg_val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        elapsed = time.time() - start_time\n",
    "        elapsed_str = str(timedelta(seconds=int(elapsed)))\n",
    "        \n",
    "        # Log epoch results\n",
    "        log_message = (f\"Final Model | Duration: {elapsed_str} | Epoch: {epoch+1}/{num_epochs} | \"\n",
    "                      f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | \"\n",
    "                      f\"LR: {current_lr:.6f}\")\n",
    "        \n",
    "        with open('optuna_training.log', 'a') as log_file:\n",
    "            log_file.write(log_message + \"\\n\")\n",
    "        \n",
    "        # Check for best validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            counter = 0\n",
    "            \n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), os.path.join(\"best\", 'best_model.pth'))\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter > patience:\n",
    "                with open('optuna_training.log', 'a') as log_file:\n",
    "                    log_file.write(f\"Final Model | Early stopping triggered at epoch {epoch+1}\\n\")\n",
    "                break\n",
    "    \n",
    "    # Plot training and validation losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss (Best Model)')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"best\", 'loss_curve.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Return model and history\n",
    "    history = {\n",
    "        'train_loss': train_losses,\n",
    "        'val_loss': val_losses,\n",
    "        'best_val_loss': best_val_loss\n",
    "    }\n",
    "    \n",
    "    return model, history, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def denormalize_from_range(normalized_data, col_min=0, col_max=100):\n",
    "    \"\"\"Convert data from [-1, 1] back to [col_min, col_max]\"\"\"\n",
    "    return col_min + (normalized_data + 1) * (col_max - col_min) / 2\n",
    "\n",
    "def predictions_best_model(test_loader, best_params, best_model_path='best/best_model.pth', col_min=None, col_max=None):\n",
    "   \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize the model with the best hyperparameters\n",
    "    model = SEM_Model(\n",
    "        dropout1=best_params['dropout1'],\n",
    "        dropout2=best_params['dropout2'],\n",
    "        fc_hidden1=best_params['hidden1'],\n",
    "        fc_hidden2=best_params['hidden2']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load the model weights\n",
    "    if not os.path.exists(best_model_path):\n",
    "        raise FileNotFoundError(f\"Best model not found at {best_model_path}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device, weights_only=True))\n",
    "    model.eval()\n",
    "    \n",
    "    # Evaluate on test data\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, selectors, values in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            selectors = selectors.to(device)\n",
    "            values = values.to(device).unsqueeze(1)\n",
    "\n",
    "            outputs = model(imgs, selectors)\n",
    "            all_predictions.append(outputs.cpu().numpy())\n",
    "            all_targets.append(values.cpu().numpy())\n",
    "    \n",
    "    # Combine predictions and targets\n",
    "    predictions = np.vstack(all_predictions)\n",
    "    targets = np.vstack(all_targets)\n",
    "\n",
    "      # Denormalize predictions and targets from [-1, 1] back to [0, 100]\n",
    "    predictions_original_scale = denormalize_from_range(predictions, col_min, col_max)\n",
    "    targets_original_scale = denormalize_from_range(targets, col_min, col_max)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(targets_original_scale, predictions_original_scale)\n",
    "    mae = mean_absolute_error(targets_original_scale, predictions_original_scale)\n",
    "    r2 = r2_score(targets_original_scale, predictions_original_scale)\n",
    "    \n",
    "    metrics = {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²-Score: {r2:.4f}\")\n",
    "    \n",
    "    # Plot actual vs. predicted values (using original scale)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(targets_original_scale, predictions_original_scale, alpha=0.5, label='Data Points')\n",
    "    plt.plot([targets_original_scale.min(), targets_original_scale.max()], \n",
    "             [targets_original_scale.min(), targets_original_scale.max()], 'r--', label='Ideal Fit')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('Actual vs. Predicted Values (Original Scale 0-100)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save and show plot\n",
    "    plt.savefig('actual_vs_predicted.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 10:22:22,595] A new study created in memory with name: no-name-5be9e500-149a-4cb9-b546-19e7cd03df71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization with 1 trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create study directory\n",
    "    study_name = \"sem_study\"\n",
    "    os.makedirs(study_name, exist_ok=True)\n",
    "    \n",
    "    # Initialize log file\n",
    "    with open(f'{study_name}/training.log', 'w') as log_file:\n",
    "        log_file.write(f\"Study started at: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "    # Create optimizer instance with a study name for saving results\n",
    "    import optuna\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    \n",
    "    # Run X trials for testing (increase for actual optimization)\n",
    "    n_trials = 2000\n",
    "    \n",
    "    print(f\"Starting hyperparameter optimization with {n_trials} trials...\")\n",
    "    \n",
    "    for trial_num in range(n_trials):\n",
    "        trial = study.ask()\n",
    "        \n",
    "        try:\n",
    "            # Call objective function directly\n",
    "            val_loss = objective(trial, train_data, val_data, test_data, study_name)\n",
    "            study.tell(trial, val_loss)\n",
    "            print(f\"Trial {trial_num+1}/{n_trials} completed with validation loss: {val_loss:.4f}\")\n",
    "        except Exception as e:\n",
    "            study.tell(trial, float('inf'))\n",
    "            print(f\"Trial {trial_num+1}/{n_trials} failed with error: {str(e)}\")\n",
    "    \n",
    "    # Get best trial\n",
    "    best_trial = study.best_trial\n",
    "    best_params = best_trial.params\n",
    "    \n",
    "    print(\"\\nOptimization completed!\")\n",
    "    print(f\"Best trial: {best_trial.number}\")\n",
    "    print(f\"Best validation loss: {best_trial.value:.4f}\")\n",
    "    print(\"Best hyperparameters:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Save best hyperparameters\n",
    "    os.makedirs(\"best\", exist_ok=True)\n",
    "    \n",
    "    # Create and train the final model with the best parameters\n",
    "    print(\"\\nTraining final model with best hyperparameters...\")\n",
    "    # Use the exact architecture parameters from the best trial\n",
    "    final_model = train_final_model(best_params, train_data, val_data, test_data)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 143.2737\n",
      "MAE: 9.3662\n",
      "R²-Score: 0.8532\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "mse: 143.2737\n",
      "mae: 9.3662\n",
      "r2: 0.8532\n"
     ]
    }
   ],
   "source": [
    "metrics = predictions_best_model(\n",
    "    test_loader=test_loader, best_params=best_params, best_model_path='best/best_model.pth', \n",
    "    col_min=0, col_max=100)\n",
    "    \n",
    "print(\"Test Metrics:\")\n",
    "for name, value in metrics.items():\n",
    "        print(f\"{name}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
